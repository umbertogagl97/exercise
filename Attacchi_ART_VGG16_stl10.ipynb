{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attacchi ART VGG16_stl10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nGmEBN4oxqUO",
        "-ycpjmyb4Cxe",
        "dherpFOH0Uau",
        "5X10jetEyAax",
        "9XepXK-ny3XN",
        "l8z4jggt3ZUG",
        "tFFWkmjX2j5P",
        "VjnPQ4NtzzQH",
        "_UByTbhH01i3",
        "Suibji7V0I7j",
        "nH0_wJWt2XuF",
        "nLcnge6A0Npi",
        "nkdhgkab0e-B",
        "fHJP8DBX0k90"
      ],
      "toc_visible": true,
      "mount_file_id": "1LFvCjg8zmdzf9GGORH3M3sLCejtQ0qUI",
      "authorship_tag": "ABX9TyN8KkFKHU+T6kDBDZo20BhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogagl97/exercise/blob/main/Attacchi_ART_VGG16_stl10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGmEBN4oxqUO"
      },
      "source": [
        "# **Import iniziali**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHENSlCXxzcr"
      },
      "source": [
        "Import ART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKN5Oqa-i6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7ac73b-64f9-4bbd-bb6d-6d15d5d6b9e4"
      },
      "source": [
        "#importa ART\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
            "Requirement already satisfied: numba~=0.53.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.53.1)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba~=0.53.1->adversarial-robustness-toolbox) (0.36.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHA120xNx0-M"
      },
      "source": [
        "Librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RXI-DDIb3C"
      },
      "source": [
        "#Librerie\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import KerasClassifier\n",
        "from art.utils import load_dataset\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycpjmyb4Cxe"
      },
      "source": [
        "#**Def variabili**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMuySVI4GgY"
      },
      "source": [
        "#salvataggio modello\n",
        "model_save_name = 'model.pt'\n",
        "path_model_save = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "\n",
        "#immagini google\n",
        "path_img_google=\"/content/gdrive/MyDrive/immagini_google/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dherpFOH0Uau"
      },
      "source": [
        "# **Collegamento google driv**e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyvTOQw-aHRP",
        "outputId": "144f271b-72f6-45fa-b690-a9dbec9c148b"
      },
      "source": [
        "#collegamento google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X10jetEyAax"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAtct4Tjyb0t"
      },
      "source": [
        "Load dataset stl10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hypnJdQu8lY"
      },
      "source": [
        "#10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.\n",
        "#96x96 pixels, colored.\n",
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"stl10\")) #carica train e test set"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez_iiYZtu_-E",
        "outputId": "ace6bd02-b4e1-4974-e7b6-e1593c3535c0"
      },
      "source": [
        "print(x_train.shape,x_test.shape)\n",
        "#5000 immagini di train e 8000 di test: 500 train e 800 test per ogni classe"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 96, 96, 3) (8000, 96, 96, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbwKfK6vwaKF"
      },
      "source": [
        "Riduzione training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kN7edZRAIwf"
      },
      "source": [
        "#x_train, y_train = x_train[:500], y_train[:500] #prende solo le prime 500 immagini di training\n",
        "x_test, y_test = x_test[:500], y_test[:500] #e le prime 10 di test"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOY_tKeRyrTL"
      },
      "source": [
        "Stampa dimensioni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtNBe7ocyqyw",
        "outputId": "2895169a-a45e-4dd3-e4df-315cc348ad9b"
      },
      "source": [
        "im_shape = x_train[0].shape\n",
        "print(\"dimensioni immagine: \",im_shape)\n",
        "print(\"dimensioni train set: \",x_train.shape)\n",
        "print(\"dimensioni vettore classi reali: \",y_train.shape)\n",
        "print(\"dimensioni test set: \",x_test.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimensioni immagine:  (96, 96, 3)\n",
            "dimensioni train set:  (5000, 96, 96, 3)\n",
            "dimensioni vettore classi reali:  (5000, 10)\n",
            "dimensioni test set:  (500, 96, 96, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XepXK-ny3XN"
      },
      "source": [
        "# **Creazione modello**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf4-dqLky7m0"
      },
      "source": [
        "load vgg16 e freeze livelli inferiori"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymaBXhaPMvL"
      },
      "source": [
        "#creazione rete usando vgg16 preaddestrata e aggiungendo gli ultimi livelli per adattarla al problema di 10 classi\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "#importa rete vgg16 addestrata sul dataset imagenet, esclude gli ultimi livelli e come input pongo dimensioni 96,96,3 \n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(im_shape[0],im_shape[1],im_shape[2]))\n",
        "\n",
        "# Freeze all the layers (non modifico i pesi dei livelli inferiori)\n",
        "for layer in vgg_conv.layers[:]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyBgJAA6zJcI"
      },
      "source": [
        "Aggiunta livelli superiori"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h_fBDmpzFa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500ae998-00de-4702-b6c7-b3a8bd7c288d"
      },
      "source": [
        "# creo un modello aggiungendo livelli alla rete importata\n",
        "model = Sequential()\n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        "# Add new layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) #10: numero di valori in uscita (le classi)\n",
        "\n",
        "#stampa info del modello\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 3, 3, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              4719616   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 19,444,554\n",
            "Trainable params: 4,729,866\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8z4jggt3ZUG"
      },
      "source": [
        "#Caricamento modello da drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOb77pSE3cyB"
      },
      "source": [
        "#load model\n",
        "model.load_state_dict(torch.load(path_model_save))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkxmNsf41B6Y"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZko74RzzcCr"
      },
      "source": [
        "Configura parametri modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfXtu3eazk5l"
      },
      "source": [
        "# Configure the model for training (setta i parametri del modello)\n",
        "import keras\n",
        "model.compile(\n",
        "        loss=keras.losses.categorical_crossentropy, optimizer=Adam(learning_rate=1e-3), metrics=[\"accuracy\"]\n",
        "    )"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-b3YpaWznuq"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr5rYORYzNxu",
        "outputId": "51ff0593-8790-4bd6-8b54-f97b4122c380"
      },
      "source": [
        "# Train the model: divisione del training set in training e validation con rapporto 80-20\n",
        "history= model.fit(x_train,y_train,epochs=20,batch_size=128)#,validation_split=0.2)\n",
        "#batch 64, lr -5, 35 epoche = 70%\n",
        "#batch 128, lr -3, 20 epoche = 98% --- test set 500 elementi: 69%, re-training senza validation acc test=69%\n",
        "#batch 128, lr -3, 25 epoche =\n",
        "#batch 128, lr -4, 20 epoche = 92%\n",
        "#batch 64, lr -4, 20 epoche = 95%"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 5000 samples\n",
            "Epoch 1/20\n",
            "5000/5000 [==============================] - 9s 2ms/sample - loss: 1.5230 - accuracy: 0.4878\n",
            "Epoch 2/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.8861 - accuracy: 0.6820\n",
            "Epoch 3/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.7535 - accuracy: 0.7282\n",
            "Epoch 4/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.6348 - accuracy: 0.7682\n",
            "Epoch 5/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.5792 - accuracy: 0.7960\n",
            "Epoch 6/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.5296 - accuracy: 0.8098\n",
            "Epoch 7/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.4487 - accuracy: 0.8384\n",
            "Epoch 8/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.4033 - accuracy: 0.8592\n",
            "Epoch 9/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.3318 - accuracy: 0.8870\n",
            "Epoch 10/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.3138 - accuracy: 0.8970\n",
            "Epoch 11/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.2477 - accuracy: 0.9176\n",
            "Epoch 12/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.2143 - accuracy: 0.9358\n",
            "Epoch 13/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1910 - accuracy: 0.9438\n",
            "Epoch 14/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1738 - accuracy: 0.9494\n",
            "Epoch 15/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.2372 - accuracy: 0.9162\n",
            "Epoch 16/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1659 - accuracy: 0.9522\n",
            "Epoch 17/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1322 - accuracy: 0.9644\n",
            "Epoch 18/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1355 - accuracy: 0.9616\n",
            "Epoch 19/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1418 - accuracy: 0.9596\n",
            "Epoch 20/20\n",
            "5000/5000 [==============================] - 8s 2ms/sample - loss: 0.1570 - accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFFWkmjX2j5P"
      },
      "source": [
        "#Salvataggio modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAie77UO2nTs"
      },
      "source": [
        "#salva modello su drive\n",
        "torch.save(model.state_dict(), path_model_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjnPQ4NtzzQH"
      },
      "source": [
        "# **Creazione classificatore ART**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWZ_zpbiZjyd"
      },
      "source": [
        "#creazione classificatore di tipo Keras usando il modello addestrato, poiché ART supporta solo determinati classificatori\n",
        "classifier = KerasClassifier(model=model, clip_values=(min_, max_)) #è un wrapper messo a disposizione da ART per creare un classificatore a partire da un modello addestrato"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UByTbhH01i3"
      },
      "source": [
        "# Esempio resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyuRBEcgsiN7"
      },
      "source": [
        "#resized=cv2.resize(x_test1[1,:,:,:],(500,500),interpolation=cv2.INTER_CUBIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X4ZaKM8z9hk"
      },
      "source": [
        "# **Testing su immagini originali**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvPxa40rAgpa",
        "outputId": "b233637e-3a2a-46e8-96ab-541504e100bc"
      },
      "source": [
        "# Evaluate the classifier on the test set \n",
        "value_preds=classifier.predict(x_test) #contiene i valori tra 0 e 1 predetti per ognuna delle 10 classi e per ogni immagine\n",
        "preds = np.argmax(value_preds, axis=1) #(le predizioni vanno da 0 a 9 e indicano la classe predetta)\n",
        "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "print(\"Accuracy on test set:\", (acc * 100))\n",
        "print(\"classi predette: \",preds)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 69.8\n",
            "classi predette:  [6 7 5 8 5 1 6 1 4 3 0 0 4 0 7 3 4 9 0 6 6 6 1 3 2 6 5 5 2 3 0 6 7 7 9 2 4\n",
            " 3 9 5 1 9 0 6 4 9 1 0 3 2 5 7 6 0 8 8 6 6 2 9 0 3 5 7 9 6 1 8 0 4 2 1 7 7\n",
            " 2 7 3 3 5 7 5 0 9 4 8 3 3 0 0 7 9 3 3 6 5 1 7 6 8 5 8 3 0 2 8 7 1 2 3 4 3\n",
            " 0 6 3 9 0 3 4 9 1 6 1 8 3 2 7 8 5 4 3 6 8 7 7 1 4 0 1 6 7 1 7 1 1 4 6 9 9\n",
            " 6 4 3 8 7 5 0 3 4 1 9 8 6 6 5 4 5 9 9 6 0 6 6 1 4 4 9 2 3 3 1 2 0 5 8 7 8\n",
            " 7 7 2 6 9 6 9 2 8 8 4 8 8 1 4 2 7 8 6 4 3 4 4 2 5 9 4 8 3 4 3 2 5 1 1 0 0\n",
            " 8 4 2 0 4 3 9 8 7 2 9 0 6 1 4 8 5 9 8 0 8 9 0 5 1 6 0 6 0 2 9 4 7 6 3 4 5\n",
            " 7 6 1 6 9 2 4 9 2 5 7 8 2 7 8 1 1 9 0 9 8 6 1 8 0 0 2 9 0 9 1 8 1 7 3 3 3\n",
            " 4 9 9 4 8 9 3 9 4 3 0 1 6 7 1 4 5 2 5 0 6 2 9 5 9 4 5 5 3 4 6 6 0 9 1 1 2\n",
            " 6 8 1 1 6 9 0 6 9 6 9 4 1 4 9 8 3 6 3 9 3 4 3 6 6 2 8 6 1 8 5 5 3 8 5 1 2\n",
            " 6 9 3 4 8 9 9 3 3 1 9 2 1 4 5 3 3 1 8 0 9 4 0 4 3 6 4 0 4 0 1 5 9 4 2 0 9\n",
            " 2 7 2 3 7 6 8 0 7 7 2 0 9 7 1 0 3 2 3 2 5 5 9 8 6 6 4 3 3 1 2 2 2 8 8 0 4\n",
            " 0 4 5 5 9 6 1 7 8 8 6 6 0 5 1 2 8 6 5 3 7 4 4 9 7 1 2 9 4 1 1 6 5 3 6 3 0\n",
            " 5 0 1 2 2 8 3 5 5 4 0 8 7 9 7 3 9 6 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suibji7V0I7j"
      },
      "source": [
        "# **Attacco**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq6B6unj2HcX"
      },
      "source": [
        "Definizione attacco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ-ghSjs2Ma0"
      },
      "source": [
        "# FGM\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYPmQSaL2Oxa"
      },
      "source": [
        "Generazione adversarial samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl_FoOil2SrO"
      },
      "source": [
        "x_test_adv = attack.generate(x=x_test,y=y_test) #aggiunge una perturbazione alle immagini del test set\n",
        "#N.B. si possono passare le classi reali del test set (con y=y_test) e in questo caso FGM calcolerà le perturbazioni in modo che il classificatore\n",
        "#non predica queste classi. Mentre, se non passo y_test, le calcolerà in modo da non fargli predire la classe predetta normalmente (la quale può essere diversa da quella reale\n",
        "#se il classificatore non è corretto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3kr1yAn2UBl"
      },
      "source": [
        "Calcolo perturbazioni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgPraX51Z15a"
      },
      "source": [
        "perturb=x_test_adv-x_test #calcolo della perturbazione\n",
        "\n",
        "#N.B. problema nel calcolo della perturbazione, con la sottrazione si ha un'immagine [-1,1], di seguito è normalizzata in [0,1]\n",
        "min_p, max_p = np.amin(perturb), np.amax(perturb)\n",
        "perturb = (perturb - min_p) / (max_p - min_p)\n",
        "#se non normalizzo, la funzione che uso per stampare ritaglia automaticamente nell'intervallo [0,1] quindi perdo informazioni"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH0_wJWt2XuF"
      },
      "source": [
        "#**Testing su immagini perturbate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V00SgiXfaAFl",
        "outputId": "beac1a52-a4bd-4cfc-9930-9b1678fd1a45"
      },
      "source": [
        "# Evaluate the classifier on the adversarial samples FGM\n",
        "value_preds_after=classifier.predict(x_test_adv)\n",
        "preds_after = np.argmax(value_preds_after, axis=1)\n",
        "acc_after = np.sum(preds_after == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "print(\"Accuracy on adversarial samples:\", (acc_after * 100))\n",
        "print(\"classi predette su test set perturbato: \",preds_after)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on adversarial samples: 0.0\n",
            "classi predette su test set perturbato:  [4 3 3 3 5 6 6 4 5 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLcnge6A0Npi"
      },
      "source": [
        "# **Stampa subplot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB1Q6Id6_CNR"
      },
      "source": [
        "#stampa subplot\n",
        "\n",
        "#cv2_imshow(cv2.hconcat([x_test[0,:,:,:]*255,x_test[1,:,:,:]*255,x_test[2,:,:,:]*255]))\n",
        "#N.B. plt.imshow usa range 0,1 per immagini rgb, mentre cv2 usa 0,255\n",
        "import matplotlib.pyplot as plt    \n",
        "#nel seguente ciclo for si crea un vettore delle classi predette ordinato per probabilità decrescente\n",
        "for i in range(x_test.shape[0]):\n",
        "  value=value_preds_after[i,:]\n",
        "  value_sorted=sorted(value,reverse=True)\n",
        "  classes=[]\n",
        "  for j in range(value.size) :\n",
        "    ind=np.where(value==value_sorted[j]) #restituisce l'indice in value del valore uguale a value_sorted[i], quindi è la classe\n",
        "    classes.append(ind[0][0]) #classes è il vettore finale\n",
        "  \n",
        "  #in seguito per ogni immagine del test set si stampa un subplot\n",
        "  fig = plt.figure()\n",
        "  print(\"Immagine \",i)\n",
        "  #originale\n",
        "  ax1 = fig.add_subplot(321) #subplot con 3 righe e due colonne\n",
        "  ax1.axis('off')\n",
        "  ax1.imshow(cv2.rotate(x_test[i,:,:,:],cv2.cv2.ROTATE_90_CLOCKWISE))\n",
        "  ax1.title.set_text(\"originale\\nclasse reale: \"+str(np.argmax(y_test[i,:]))+\"\\nclasse predetta: \"+str(preds[i]))\n",
        "  #perturbazione\n",
        "  ax2 = fig.add_subplot(322)\n",
        "  ax2.imshow(cv2.rotate(perturb[i,:,:,:],cv2.cv2.ROTATE_90_CLOCKWISE))\n",
        "  ax2.axis('off')\n",
        "  ax2.title.set_text(\"perturbazione\")\n",
        "  #perturbata\n",
        "  ax3 = fig.add_subplot(325)\n",
        "  ax3.imshow(cv2.rotate(x_test_adv[i,:,:,:],cv2.cv2.ROTATE_90_CLOCKWISE))\n",
        "  ax3.axis('off')\n",
        "  ax3.title.set_text(\"perturbata\\ntop5 classi predette: \"+str(classes[:5])+\"\\ncon i valori: \"+str(value_sorted[:5]))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkdhgkab0e-B"
      },
      "source": [
        "# Def funzione che perturba una singola immagine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkTzu6ZAcbgU"
      },
      "source": [
        "def perturb_img(img_g : np.ndarray,real_class : int):\n",
        "  img_g=cv2.resize(img_g,(96,96))\n",
        "  print(\"\\nImmagine originale, classe reale: \",real_class)\n",
        "  cv2_imshow(img_g)\n",
        "\n",
        "  min_, max_ = np.amin(img_g), np.amax(img_g)\n",
        "  normalized_img_g = (img_g - min_) / (max_ - min_) #normalizzo tra [0,1]\n",
        "  normalized_img_g=normalized_img_g.reshape(1,96,96,3)\n",
        "\n",
        "  pred_value=classifier.predict(normalized_img_g)\n",
        "  pred=np.argmax(pred_value)\n",
        "  print(\"Classe predetta: \",pred)\n",
        "  print(\"Valori predetti per ogni classe:\\n\",pred_value)\n",
        "  #generazione perturbazione\n",
        "  img_adv = attack.generate(x=normalized_img_g)\n",
        "  print(\"\\nImmagine perturbata\")\n",
        "  cv2_imshow(img_adv[0,:,:,:]*max_)\n",
        "  pred_value_adv=classifier.predict(img_adv)\n",
        "  pred_adv=np.argmax(pred_value_adv)\n",
        "  print(\"Classe predetta: \",pred_adv)\n",
        "  print(\"Valori predetti per ogni classe:\\n\",pred_value_adv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHJP8DBX0k90"
      },
      "source": [
        "# Testing su immagine di google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcVXbpP3TBk8"
      },
      "source": [
        "#test su immagini di google\n",
        "\n",
        "#10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.\n",
        "\n",
        "img_g1=cv2.imread(path_img_drive+\"airplane.jpg\")\n",
        "img_g2=cv2.imread(path_img_drive+\"dog.jpg\")\n",
        "\n",
        "perturb_img(img_g1,0)\n",
        "perturb_img(img_g2,5)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}